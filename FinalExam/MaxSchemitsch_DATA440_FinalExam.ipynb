{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaxSchemitsch_DATA440_FinalExam.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrdJcOAR9SJ3",
        "colab_type": "text"
      },
      "source": [
        "#Problem 1: Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vnxlYxRpaCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import finalGenData\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# number of samples\n",
        "N = 1000\n",
        "\n",
        "# generate data & split it into X (training input) and y (target output)\n",
        "X, y = finalGenData.genDataSet(N)\n",
        "\n",
        "# linear regression solution\n",
        "w=np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "\n",
        "\n",
        "#penC  <- Penalty parameter C of the error term\n",
        "#tubEpsilon  <- the epsilon-tube within which no penalty is associated\n",
        "\n",
        "bestC=0\n",
        "bestEpsilon=0\n",
        "bestGamma=0\n",
        "bestScore=float('-inf')\n",
        "score=0\n",
        "for penC in np.logspace(-5, 15, num=11, base=2):\n",
        "  for tubEpsilon in np.linspace(0, 1, num=11):\n",
        "    for paramGamma in np.logspace(-15, 3, num=10, base=2):\n",
        "      kf = KFold(n_splits=10)\n",
        "      cvscore=[]\n",
        "      for train, validation in kf.split(X):\n",
        "        X_train, X_validation, y_train, y_validation = X[train, :], X[validation, :], y[train], y[validation]\n",
        "        # here we create the SVR\n",
        "        svr =  SVR(C=penC, epsilon=tubEpsilon, gamma=paramGamma, kernel='rbf', verbose=False)\n",
        "        # here we train the SVR\n",
        "        svr.fit(X_train, y_train)\n",
        "        # now we get E_out for validation set\n",
        "        score=svr.score(X_validation, y_validation)\n",
        "        cvscore.append(score)\n",
        "\n",
        "      # average CV score\n",
        "      score=sum(cvscore)/len(cvscore)\n",
        "      if (score > bestScore):\n",
        "        bestScore=score\n",
        "        bestC=penC\n",
        "        bestEpsilon=tubEpsilon\n",
        "        bestGamma=paramGamma\n",
        "        print(\"C \" + str(penC) + \", epsilon \" + str(tubEpsilon) + \", gamma \" + str(paramGamma) + \". Testing set CV score: %f\" % score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKKyjg4s9g5z",
        "colab_type": "text"
      },
      "source": [
        "# Plotting SVR Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM7YuhRFp01Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here we get a new training dataset\n",
        "X, y = finalGenData.genDataSet(N)\n",
        "# here we create the final SVR\n",
        "svr =  SVR(C=bestC, epsilon=bestEpsilon, gamma=bestGamma, kernel='rbf', verbose=True)\n",
        "# here we train the final SVR\n",
        "svr.fit(X, y)\n",
        "# E_out in training\n",
        "print(\"Training set score: %f\" % svr.score(X, y)) \n",
        "# here we get a new testing dataset\n",
        "X, y = finalGenData.genDataSet(N)\n",
        "# here test the final SVR and get E_out for testing set\n",
        "ypred=svr.predict(X)\n",
        "score=svr.score(X, y)\n",
        "print(\"Testing set score: %f\" % score)\n",
        "plt.plot(X[:, 0], X[:, 1], '.')\n",
        "plt.plot(X[:, 0], y, 'rx')\n",
        "plt.plot(X[:, 0], ypred, '-k')\n",
        "ypredLR=X.dot(w)\n",
        "plt.plot(X[:, 0], ypredLR, '--g')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obYCOtJ298Hw",
        "colab_type": "text"
      },
      "source": [
        "# Problem 2: More Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzdkccfdzYZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import finalGetDigits\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# get digits data X (training input) and y (target output)\n",
        "X, y, X_te, y_te = finalGetDigits.getDataSet()\n",
        "\n",
        "#penC  <- Penalty parameter C of the error term\n",
        "#tubEpsilon  <- the epsilon-tube within which no penalty is associated\n",
        "\n",
        "bestC=0\n",
        "bestEpsilon=0\n",
        "bestGamma=0\n",
        "bestScore=float('-inf')\n",
        "score=0\n",
        "\n",
        "for penC in np.logspace(6, 12, num=7, base=2):\n",
        "  for tubEpsilon in np.linspace(0.5, 2.5, num=21):\n",
        "    for paramGamma in np.logspace(-6, -2, num=5, base=2):\n",
        "      kf = KFold(n_splits=np.random.randint(2,11))\n",
        "      cvscore=[]\n",
        "      for train, validation in kf.split(X):\n",
        "        X_train, X_validation, y_train, y_validation = X[train, :], X[validation, :], y[train], y[validation]\n",
        "        # here we create the SVR\n",
        "        svr =  SVR(C=penC, epsilon=tubEpsilon, gamma=paramGamma, kernel='rbf', verbose=False)\n",
        "        # here we train the SVR\n",
        "        svr.fit(X_train, y_train)\n",
        "        # now we get E_out for validation set\n",
        "        score=svr.score(X_validation, y_validation)\n",
        "        cvscore.append(score)\n",
        "\n",
        "      # average CV score\n",
        "      score=sum(cvscore)/len(cvscore)\n",
        "      if (score > bestScore):\n",
        "        bestScore=score\n",
        "        bestC=penC\n",
        "        bestEpsilon=tubEpsilon\n",
        "        bestGamma=paramGamma\n",
        "        print(\"BEST! -> C \" + str(penC) + \", epsilon \" + str(tubEpsilon) + \", gamma \" + str(paramGamma) + \". Testing set CV score: %f\" % score)\n",
        "      else:\n",
        "        print(\"C \" + str(penC) + \", epsilon \" + str(tubEpsilon) + \", gamma \" + str(paramGamma) + \". Testing set CV score: %f\" % score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCNMSbO19_Lm",
        "colab_type": "text"
      },
      "source": [
        "# Plotting SVR Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcgeWyk4-ahG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmap = cm.get_cmap(\"Spectral\")\n",
        "\n",
        "# here we create the final SVR\n",
        "svr =  SVR(C=bestC, epsilon=bestEpsilon, gamma=bestGamma, kernel='rbf', verbose=True)\n",
        "# here we train the final SVR\n",
        "svr.fit(X, y)\n",
        "# E_out in training\n",
        "print(\"Training set score: %f\" % svr.score(X, y)) \n",
        "# here test the final SVR and get E_out for testing set\n",
        "ypred=svr.predict(X_te)\n",
        "score=svr.score(X_te, y_te)\n",
        "print(\"Testing set score: %f\" % score)\n",
        "\n",
        "x_min, x_max = np.min(X_te, axis=0), np.max(X_te, axis=0)\n",
        "X_te = (X_te - x_min) / (x_max - x_min)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "for i in range(X_te.shape[0]):\n",
        "  plt.text(X_te[i, 0], X_te[i, 1], str(y_te[i]), color=cmap(round(ypred[i]) / 10.), fontdict={'weight': 'bold', 'size': 9})\n",
        "\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}