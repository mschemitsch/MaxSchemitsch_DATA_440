# -*- coding: utf-8 -*-
"""HW3 Problem1and2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yrNRVWrrmeIutPBNhPrBD0ffjcWJtj2z
"""

import numpy as np
from matplotlib import pyplot as plt

def genDataSet(N):
    x = np.random.normal(0, 1, N)
    ytrue = (np.cos(x) + 2) / (np.cos(x * 1.4) + 2)
    noise = np.random.normal(0, 0.2, N)
    y = ytrue + noise
    return x, y, ytrue

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold

kf = KFold(n_splits=10)

bestkall = []
for i in range(100):
  x, y, ytrue = genDataSet(1000)
  X = np.array([x,y]).T
  kf.get_n_splits(X)
  
  msek = {}
  #plt.figure(figsize=(7,7))
  bestk = 0
  bestmse = 100000
  for k in np.arange(1, 2*np.floor(((len(ytrue)*0.9)+1)/2), 2):
    #print(k)
    mse = []
    for train_index, test_index in kf.split(X):
      X_train, X_test =     X[train_index],     X[test_index]
      y_train, y_test = ytrue[train_index], ytrue[test_index]

      neigh = KNeighborsRegressor(n_neighbors=int(k))
      neigh.fit(X_train, y_train)
      predictions = neigh.predict(X_test)

      mse.append(mean_squared_error(y_test, predictions))

    #print(np.mean(mse))
    msek[k]=np.mean(mse)
    if bestmse > msek[k]:
      bestmse = msek[k]
      bestk = k
      #print(bestk, bestmse)
    
  bestkall.append(bestk)
  #plt.plot(k,msek[k],'r.') 

#plt.show()
#print(bestkall)
plt.hist(bestkall)

from statistics import mode

neigh = KNeighborsRegressor(n_neighbors=int(mode(bestkall)))
neigh.fit(X, ytrue)
predictions = neigh.predict(X)

plt.plot(x,y,'.')
plt.plot(x,ytrue,'rx')
plt.plot(x,predictions,'g.')
plt.show()

